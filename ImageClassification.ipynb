{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamAzizi/ComputerVision/blob/main/ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lVccwPrHjqi"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "import numpy as np\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHYn5DF7P0lE",
        "outputId": "90785c42-8b3a-4bc7-acfc-f7cb74565349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "gdrive_cwd = '/content/gdrive/My Drive/Colab Notebooks'\n",
        "dataset_dir = os.path.join(gdrive_cwd, 'Classification_Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs_8CxkfOnWa"
      },
      "outputs": [],
      "source": [
        "img_h = 32\n",
        "img_w = 32\n",
        "bs = 8\n",
        "nb_epoch = 50\n",
        "verbose = 1\n",
        "validation_split = 0.01\n",
        "SEED = 8585\n",
        "optim = RMSprop()\n",
        "num_classes = 20\n",
        "classes_list = [\n",
        "               'owl',               # 0\n",
        "               'galaxy',            # 1\n",
        "               'lightning',         # 2\n",
        "               'wine-bottle',       # 3\n",
        "               't-shirt',           # 4\n",
        "               'waterfall',         # 5\n",
        "               'sword',             # 6\n",
        "               'school-bus',        # 7\n",
        "               'calculator',        # 8\n",
        "               'sheet-music',       # 9\n",
        "               'airplanes',         # 10\n",
        "               'lightbulb',         # 11\n",
        "               'skyscraper',        # 12\n",
        "               'mountain-bike',     # 13\n",
        "               'fireworks',         # 14\n",
        "               'computer-monitor',  # 15\n",
        "               'bear',              # 16\n",
        "               'grand-piano',       # 17\n",
        "               'kangaroo',          # 18\n",
        "               'laptop']           # 19\n",
        "color_mode = 'rgb' \n",
        "img_ch = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzs2ljy-QGEz",
        "outputId": "664137e2-6047-4520-88cd-ca6c695c126b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1522 images belonging to 20 classes.\n",
            "Found 3 images belonging to 20 classes.\n"
          ]
        }
      ],
      "source": [
        "# ImageDataGenerator\n",
        "image_data_generator = ImageDataGenerator(rotation_range=40,\n",
        "                                          width_shift_range=.2,\n",
        "                                          height_shift_range=.2,\n",
        "                                          zoom_range=0.3,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,                                         \n",
        "                                          fill_mode='constant',\n",
        "                                          cval=0,\n",
        "                                          rescale=1./255,\n",
        "                                          validation_split=validation_split)\n",
        "\n",
        "# Training Data Generator\n",
        "training_dir = os.path.join(dataset_dir, 'training')\n",
        "train_gen = image_data_generator.flow_from_directory(training_dir,\n",
        "                                               batch_size=bs,\n",
        "                                               color_mode=color_mode,\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=classes_list,\n",
        "                                               shuffle=True,\n",
        "                                               subset='training',\n",
        "                                               seed=SEED,\n",
        "                                               target_size=(img_h, img_w))  # targets are directly converted into one-hot vectors\n",
        "\n",
        "\n",
        "valid_gen = image_data_generator.flow_from_directory(training_dir,\n",
        "                                               batch_size=bs,\n",
        "                                               color_mode=color_mode, #rgb,grayscale\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=classes_list,\n",
        "                                               shuffle=False,\n",
        "                                               subset='validation',\n",
        "                                               seed=SEED,\n",
        "                                               target_size=(img_h, img_w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBg1X2D5Qbr2",
        "outputId": "4d5ff675-a335-4c72-9210-bea97078e185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<FlatMapDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None))>\n",
            "<FlatMapDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None))>\n",
            "Found 500 images belonging to 20 classes.\n",
            "<FlatMapDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Training data set\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, img_ch], [None, num_classes]))\n",
        "print(train_dataset)\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# Validation\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, img_ch], [None, num_classes]))\n",
        "print(valid_dataset)\n",
        "# Repeat\n",
        "valid_dataset = valid_dataset.repeat()\n",
        "\n",
        "#test data set\n",
        "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_dir = os.path.join(dataset_dir, 'test')\n",
        "test_gen = test_data_gen.flow_from_directory(test_dir,\n",
        "                                             batch_size=1,\n",
        "                                             classes=classes_list,\n",
        "                                             color_mode=color_mode,\n",
        "                                             class_mode='categorical',\n",
        "                                             shuffle=False,\n",
        "                                             target_size=(img_h, img_w),\n",
        "                                             seed=SEED)\n",
        "\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen,\n",
        "                                              output_types=(tf.float32, tf.float32),\n",
        "                                              output_shapes=([None, img_h, img_w, img_ch], [None, num_classes]))\n",
        "\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw4KLuQOSvRT"
      },
      "source": [
        "### Model architecture should be designed and implemented in this block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSCkfIu0RSnj",
        "outputId": "10100b9c-ddf9-4108-f8e4-c7e4401d805d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 5, 5, 128)         147584    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                10260     \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,076\n",
            "Trainable params: 533,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "input_shape=(img_h, img_w, img_ch)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9OFGhF4RpPJ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = optim , metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TWNNaImRs_z",
        "outputId": "f28da84d-3eda-4917-c95e-7e865b780adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 1196s 6s/step - loss: 2.9832 - accuracy: 0.0690 - val_loss: 2.5778 - val_accuracy: 0.3333\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 9s 45ms/step - loss: 2.8839 - accuracy: 0.0992 - val_loss: 2.1767 - val_accuracy: 0.3333\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 9s 45ms/step - loss: 2.7790 - accuracy: 0.1386 - val_loss: 2.4086 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 9s 45ms/step - loss: 2.7219 - accuracy: 0.1452 - val_loss: 2.2645 - val_accuracy: 0.3333\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 9s 45ms/step - loss: 2.6618 - accuracy: 0.1662 - val_loss: 2.5244 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f39638c7890>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=train_dataset,\n",
        "          epochs=5,  \n",
        "          steps_per_epoch=len(train_gen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_gen),\n",
        "          callbacks=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP3vhVqTRvgi"
      },
      "outputs": [],
      "source": [
        "test_file_names = test_gen.filenames\n",
        "predictions = model.predict_generator(test_dataset, len(test_file_names))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}