{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamAzizi/ComputerVision/blob/main/ImageSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL3xAVI89dau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd64226-c14b-4440-cd4f-9df3d4bbdc46"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import os\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for random operations. \n",
        "# This let our experiments to be reproducible. \n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)  \n",
        "#np.random.seed = SEED\n",
        "\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0': \n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl0EU3dB9363"
      },
      "source": [
        "# ImageDataGenerator\n",
        "# ------------------\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "validation_split = 0.01\n",
        "apply_data_augmentation = False\n",
        "\n",
        "# Create training ImageDataGenerator object\n",
        "# We need two different generators for images and corresponding masks\n",
        "if apply_data_augmentation:\n",
        "    train_img_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                            width_shift_range=10,\n",
        "                                            height_shift_range=10,\n",
        "                                            zoom_range=0.3,\n",
        "                                            horizontal_flip=True,\n",
        "                                            vertical_flip=True,\n",
        "                                            fill_mode='constant',\n",
        "                                            cval=0,\n",
        "                                            rescale=1./255,\n",
        "                                            validation_split=validation_split)\n",
        "    \n",
        "    train_mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                             width_shift_range=10,\n",
        "                                             height_shift_range=10,\n",
        "                                             zoom_range=0.3,\n",
        "                                             horizontal_flip=True,\n",
        "                                             vertical_flip=True,\n",
        "                                             fill_mode='constant',\n",
        "                                             cval=0,\n",
        "                                             rescale=1./255,\n",
        "                                             validation_split=validation_split)\n",
        "else:\n",
        "    train_img_data_gen = ImageDataGenerator(rescale=1./255,validation_split=validation_split)\n",
        "    train_mask_data_gen = ImageDataGenerator(rescale=1./255,validation_split=validation_split)\n",
        "\n",
        "# Create validation and test ImageDataGenerator objects\n",
        "#valid_img_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "#valid_mask_data_gen = ImageDataGenerator()\n",
        "test_img_data_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_mask_data_gen = ImageDataGenerator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQ5YJNU95_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e54b8d-bc3a-4d6f-8d44-30ae48573839"
      },
      "source": [
        "# Create generators to read images from dataset directory\n",
        "# -------------------------------------------------------\n",
        "\n",
        "# Get current working directory\n",
        "#cwd = os.getcwd()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "cwd = '/content/gdrive/My Drive'\n",
        "dataset_dir = os.path.join(cwd, 'Segmentation_Dataset')\n",
        "\n",
        "\n",
        "\n",
        "# Batch size\n",
        "bs = 10\n",
        "\n",
        "# img shape\n",
        "img_h = 256\n",
        "img_w = 256\n",
        "\n",
        "# Training\n",
        "# Two different generators for images and masks\n",
        "# ATTENTION: here the seed is important!! We have to give the same SEED to both the generator\n",
        "# to apply the same transformations/shuffling to images and corresponding masks\n",
        "training_dir = os.path.join(dataset_dir, 'training')\n",
        "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
        "                                                       target_size=(img_h, img_w),\n",
        "                                                       batch_size=bs, \n",
        "                                                       color_mode='rgb',\n",
        "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
        "                                                       shuffle=True,\n",
        "                                                       interpolation='bilinear',\n",
        "                                                       subset='training',\n",
        "                                                       seed=SEED)  \n",
        "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
        "                                                         target_size=(img_h, img_w),\n",
        "                                                         batch_size=bs,\n",
        "                                                         color_mode='grayscale',\n",
        "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
        "                                                         shuffle=True,\n",
        "                                                         interpolation='bilinear',\n",
        "                                                         subset='training',\n",
        "                                                         seed=SEED)\n",
        "train_gen = zip(train_img_gen, train_mask_gen)\n",
        "\n",
        "# Validation\n",
        "validation_dir = os.path.join(dataset_dir, 'validation')\n",
        "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
        "                                                       target_size=(img_h, img_w),\n",
        "                                                       batch_size=bs, \n",
        "                                                       color_mode='rgb',\n",
        "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
        "                                                       shuffle=False,\n",
        "                                                       interpolation='bilinear',\n",
        "                                                       subset='validation',\n",
        "                                                       seed=SEED)\n",
        "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
        "                                                         target_size=(img_h, img_w),\n",
        "                                                         batch_size=bs, \n",
        "                                                         color_mode='grayscale',\n",
        "                                                         class_mode=None, # Because we have no class subfolders in this case\n",
        "                                                         shuffle=False,\n",
        "                                                         interpolation='bilinear',\n",
        "                                                         subset='validation',\n",
        "                                                         seed=SEED)\n",
        "valid_gen = zip(valid_img_gen, valid_mask_gen)\n",
        "\n",
        "# Test\n",
        "test_dir = os.path.join(dataset_dir, 'test')\n",
        "test_dir = os.path.join(test_dir, 'images')\n",
        "test_img_gen = test_img_data_gen.flow_from_directory(test_dir,\n",
        "                                                     target_size=(img_h, img_w),\n",
        "                                                     batch_size=1, \n",
        "                                                     class_mode=None, # Because we have no class subfolders in this case\n",
        "                                                     shuffle=False,\n",
        "                                                     interpolation='bilinear',\n",
        "                                                     seed=SEED)\n",
        "\n",
        "\n",
        "#not important but to avoid error\n",
        "test_mask_gen = test_mask_data_gen.flow_from_directory(test_dir,\n",
        "                                                       target_size=(img_h, img_w),\n",
        "                                                       batch_size=bs, \n",
        "                                                       class_mode=None, # Because we have no class subfolders in this case\n",
        "                                                       shuffle=False,\n",
        "                                                       interpolation='bilinear',\n",
        "                                                       seed=SEED)\n",
        "\n",
        "test_gen = zip(test_img_gen, test_mask_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Found 7571 images belonging to 1 classes.\n",
            "Found 7571 images belonging to 1 classes.\n",
            "Found 76 images belonging to 1 classes.\n",
            "Found 76 images belonging to 1 classes.\n",
            "Found 1234 images belonging to 1 classes.\n",
            "Found 1234 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5F_ijUO-HAw"
      },
      "source": [
        "# Create Dataset objects\n",
        "# ----------------------\n",
        "\n",
        "def prepare_target(x_, y_):\n",
        "    \n",
        "    y_ = tf.cast(y_,tf.int32)\n",
        "    \n",
        "    return x_, y_\n",
        "\n",
        "\n",
        "# Training\n",
        "# --------\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
        "\n",
        "train_dataset = train_dataset.map(prepare_target)\n",
        "\n",
        "# Repeat\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# Validation\n",
        "# ----------\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
        "valid_dataset = valid_dataset.map(prepare_target)\n",
        "\n",
        "# Repeat\n",
        "valid_dataset = valid_dataset.repeat()\n",
        "\n",
        "# Test\n",
        "# ----\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen, output_types=(tf.float32, tf.float32), output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
        "test_dataset = test_dataset.map(prepare_target)\n",
        "#test_dataset = valid_dataset.repeat()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrhugL4V-J43"
      },
      "source": [
        "# Create Model\n",
        "# ------------\n",
        "\n",
        "\n",
        "def create_model(depth, start_f, num_classes, dynamic_input_shape):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    # Encoder\n",
        "    # -------\n",
        "    for i in range(depth):\n",
        "        \n",
        "        if i == 0:\n",
        "            if dynamic_input_shape:\n",
        "                input_shape = [None, None, 3]\n",
        "            else:\n",
        "                input_shape = [img_h, img_w, 3]\n",
        "        else:\n",
        "            input_shape=[None]\n",
        "        \n",
        "        model.add(tf.keras.layers.Conv2D(filters=start_f, \n",
        "                                         kernel_size=(3, 3),\n",
        "                                         strides=(1, 1),\n",
        "                                         padding='same',\n",
        "                                         input_shape=input_shape))\n",
        "        model.add(tf.keras.layers.ReLU())\n",
        "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "        start_f *= 2\n",
        "\n",
        "    # Decoder\n",
        "    # -------\n",
        "    for i in range(depth):\n",
        "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=start_f // 2,\n",
        "                                         kernel_size=(3, 3),\n",
        "                                         strides=(1, 1),\n",
        "                                         padding='same'))\n",
        "\n",
        "        model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "        start_f = start_f // 2\n",
        "\n",
        "    # Prediction Layer\n",
        "    # ----------------\n",
        "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=(1, 1),\n",
        "                                     padding='same',\n",
        "                                     activation='sigmoid')) # sigmoid\n",
        "    \n",
        "    return model\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alKNImoU-MLL"
      },
      "source": [
        "# Optimization params\n",
        "# -------------------\n",
        "model = create_model(depth=4, start_f=4, num_classes=1, dynamic_input_shape=False)   \n",
        "\n",
        "def my_IoU(y_true, y_pred):\n",
        "    # from pobability to predicted class {0, 1}\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
        "\n",
        "    # A and B\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    # A or B\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "    # IoU\n",
        "    return intersection / union\n",
        "\n",
        "# Loss\n",
        "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
        "#loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
        "loss = tf.keras.losses.BinaryCrossentropy() \n",
        "# learning rate\n",
        "lr = 1e-3\n",
        "#lr = 5e-4\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "#optimizer=keras.optimizers.Adadelta(lr)\n",
        "# -------------------\n",
        "#\n",
        "# Validation metrics\n",
        "# ------------------\n",
        "\n",
        "metrics = ['accuracy']\n",
        "# ------------------\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[my_IoU])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ICMGt15-OQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf60d64-6012-4a53-eed4-ad69c65fe51b"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "epochs = 100  #### set repeat in training dataset\n",
        "\n",
        "\n",
        "# from tensorflow.compat.v1 import ConfigProto\n",
        "# from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "# config = ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "# session = InteractiveSession(config=config)\n",
        "\n",
        "exps_dir = os.path.join(cwd, 'segmentation_experiments')\n",
        "if not os.path.exists(exps_dir):\n",
        "    os.makedirs(exps_dir)\n",
        "\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "model_name = 'CNN'\n",
        "\n",
        "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "if not os.path.exists(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "    \n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint\n",
        "# ----------------\n",
        "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
        "                                                   save_weights_only=True)  # False to save the model directly\n",
        "callbacks.append(ckpt_callback)\n",
        "\n",
        "# Visualize Learning on Tensorboard\n",
        "# ---------------------------------\n",
        "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "    \n",
        "# By default shows losses and metrics for both training and validation\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                             profile_batch=0,\n",
        "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
        "callbacks.append(tb_callback)\n",
        "\n",
        "# Early Stopping\n",
        "# --------------\n",
        "early_stop = False\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callback.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    model.fit(x=train_dataset,\n",
        "          epochs=epochs,  #### set repeat in training dataset\n",
        "          steps_per_epoch=len(train_img_gen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_img_gen), \n",
        "          callbacks=callbacks)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "159/758 [=====>........................] - ETA: 2:49:12 - loss: 0.6151 - my_IoU: 0.0047"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBgq3R8K-Qhw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8ea20653-a151-4a55-f237-fc50e6e22b94"
      },
      "source": [
        "# Just for exercise try to restore a model after training it\n",
        "# !! Use this just when restoring model.. \n",
        "# ---------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "cwd = '/content/gdrive/My Drive'\n",
        "restore_model = True\n",
        "if restore_model:\n",
        "    model = create_model(depth=4, #4\n",
        "                         start_f=4, #4\n",
        "                         num_classes=1, #3\n",
        "                         dynamic_input_shape=True)\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True) , \n",
        "                  metrics=['accuracy'])  # Needed for loading weights\n",
        "\n",
        "    load_this = os.path.join( cwd, 'segmentation_experiments', 'CNN_Dec16_20-07-25', 'ckpts', 'cp_100.ckpt')\n",
        "    print('Loading: ' + load_this)\n",
        "    model.load_weights(load_this)  # use this if you want to restore saved model\n",
        "# ----------------------------------------\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Loading: /content/gdrive/My Drive/segmentation_experiments/CNN_Dec16_20-07-25/ckpts/cp_100.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9be701ec88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1aMTfk3-RLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "032a8ee8-c911-49b5-b7aa-711b227c29a1"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "csv_fname = cwd + '/results_'\n",
        "csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "\n",
        "\n",
        "test_img_dir = os.path.join(test_dir, 'img')\n",
        "img_filenames = next(os.walk(test_img_dir))[2]\n",
        "results={}\n",
        "i=0\n",
        "\n",
        "\n",
        "def rle_encode(img):\n",
        "      # Flatten column-wise\n",
        "      pixels = img.T.flatten()\n",
        "      pixels = np.concatenate([[0], pixels, [0]])\n",
        "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "      runs[1::2] -= runs[::2]\n",
        "      return ' '.join(str(x) for x in runs)\n",
        "\n",
        "      \n",
        "with open(csv_fname, 'w') as f:\n",
        "  \n",
        "  f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
        "  for img_filename in img_filenames:\n",
        "\n",
        "     img = Image.open(os.path.join(test_img_dir, img_filename))\n",
        "     img = img.resize((img_h, img_w))\n",
        "     img_arr = np.expand_dims(np.array(img), 0)  \n",
        "     activations = model.predict(x=img_arr / 255.)\n",
        "    \n",
        "     #print (out_softmax[0,:,:,1])\n",
        "     #print (out_softmax.shape)\n",
        "     #break\n",
        "     # Get predicted class as the index corresponding to the maximum value in the vector probability\n",
        "    \n",
        "\n",
        "     #predicted_class = tf.argmax(activation, -1)\n",
        "     predicted_class = tf.where(activations>0.5,1,0) #1,0\n",
        "     #print (predicted_class)\n",
        "     #break\n",
        "     #print (predicted_class)\n",
        "\n",
        "     predicted_class = predicted_class[0]\n",
        "     #prediction_img = np.zeros([img_h, img_w, 3])\n",
        "     #prediction_img[np.where(predicted_class == 1)] = 1\n",
        "     #prediction_img[np.where(predicted_class == 2)] = 1\n",
        "\n",
        "     image_encoded = rle_encode(predicted_class.numpy())\n",
        "     results[img_filename] =   image_encoded\n",
        "     split = img_filename.split('.')\n",
        "     img_id = split[0]\n",
        "     i += 1\n",
        "     #print ('\\n' + i.__str__() + ') \\\"' + img_filename+'\\\" : ' + image_encoded)\n",
        "     print ('\\n' + i.__str__() + ') \\\"' + img_filename)\n",
        "     write_output = f.write(img_id + ',' + image_encoded + ',' + '256' + ',' + '256' + '\\n')\n",
        "\n",
        "     #break\n",
        "     #print (predicted_class)\n",
        "\n",
        "#create_csv(results,results_dir=gdrive_cwd)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1) \"2148.tif\n",
            "\n",
            "2) \"2150.tif\n",
            "\n",
            "3) \"2156.tif\n",
            "\n",
            "4) \"2157.tif\n",
            "\n",
            "5) \"2149.tif\n",
            "\n",
            "6) \"2152.tif\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-334ace60c794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimg_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_filenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m      \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m      \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m      \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy7nlBbu-S-P"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def create_csv(results, results_dir='./'):\n",
        "\n",
        "    csv_fname = gdrive_cwd + '/results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(csv_fname, 'w') as f:\n",
        "\n",
        "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
        "\n",
        "      for key, value in results.items():\n",
        "          f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}